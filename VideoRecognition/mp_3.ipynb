{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Problem 3: NumPy CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from scipy import signal\n",
    "from imageio import imread\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_images\n",
    "    # Read in images and makes a list for each set in the form: [images, labels]\n",
    "    # images: np array with dims [N x img_height x img width x num_channels]\n",
    "    # labels: np array with dims [N x 1]. elephant = 0, lionfish = 1\n",
    "    #\n",
    "    # Returns:  train_set: The list [train_images, train_labels]\n",
    "    #           val_set: The list [val_images, val_labels] \n",
    "\n",
    "def load_images():\n",
    "    \n",
    "    sets = ['train', 'val']\n",
    "    \n",
    "    data_sets = []\n",
    "    for dset in sets:\n",
    "        img_path = './bin_dataset/' + dset + '/ele'\n",
    "        ele_list = [imread(os.path.join(img_path, img)) for img in os.listdir(img_path)]\n",
    "\n",
    "        img_path = './bin_dataset/' + dset + '/lio'\n",
    "        lio_list = [imread(os.path.join(img_path, img)) for img in os.listdir(img_path)]\n",
    "\n",
    "        set_images = np.stack(ele_list + lio_list)\n",
    "        N = set_images.shape[0]\n",
    "        labels = np.ones((N,1))\n",
    "        labels[0:int(N/2)] = 0\n",
    "        data_sets.append([set_images, labels])\n",
    "\n",
    "    train_set, val_set = data_sets\n",
    "\n",
    "    print(\"Loaded\", len(train_set[0]), \"training images\")\n",
    "    print(\"Loaded\", len(val_set[0]), \"validation images\")\n",
    "    \n",
    "    return train_set, val_set\n",
    "\n",
    "\n",
    "# batchify\n",
    "    # Inputs:    train_set: List containing images and labels\n",
    "    #            batch size: The desired size of each batch\n",
    "    #\n",
    "    # Returns:   image_batches: A list of shuffled training image batches, each with size batch_size\n",
    "    #            label_batches: A list of shuffled training label batches, each with size batch_size \n",
    "\n",
    "def batchify(train_set, batch_size):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     print(len(train_set))\n",
    "#     print(len(train_set[0]))\n",
    "#     print(len(train_set[0][0]))\n",
    "#     print(len(train_set[0][0][0]))\n",
    "#     print(len(train_set[0][0][0][0]))\n",
    "    shuffle(train_set)\n",
    "    image_batches, label_batches =[],[]\n",
    "    for i in range(len(train_set[0])//batch_size):\n",
    "        batch_image = []\n",
    "        batch_label = []\n",
    "        for j in range(batch_size):\n",
    "            batch_image.append(train_set[0][i*batch_size + j])\n",
    "            batch_label.append(train_set[1][i*batch_size + j])\n",
    "        image_batches.append(batch_image)\n",
    "        label_batches.append(label_batches)\n",
    "    return image_batches, label_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu\n",
    "    # Inputs:   x: Multi-dimensional array with size N along the first axis\n",
    "    # \n",
    "    # Returns:  out: Multi-dimensional array with same size of x \n",
    "\n",
    "def relu(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    N,W,H,D = len(x),len(x[0]),len(x[0][0]),len(x[0][0][0])\n",
    "    out = np.zeros((N,W,H,D))\n",
    "    for i in range(N):\n",
    "        for j in range(W):\n",
    "            for k in range(H):\n",
    "                for l in range(D):\n",
    "                    out[i][j][k][l] = max(0,x[i][j][k][l])\n",
    "    return out\n",
    "\n",
    "def relu2(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    N,F = len(x),len(x[0])\n",
    "    out = np.zeros((N,F))\n",
    "    for i in range(N):\n",
    "        for j in range(F):\n",
    "            out[i][j] = max(0,x[i][j])\n",
    "    return out\n",
    "\n",
    "# sigmoid\n",
    "    # Inputs:    x: Multi-dimensional array with size N along the first axis\n",
    "    # \n",
    "    # Returns:   out: Multi-dimensional array with same size of x \n",
    "\n",
    "def sigmoid(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    N = len(x)\n",
    "    out = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        out[i] = sig_help(x[i])\n",
    "    return out\n",
    "\n",
    "def sig_help(x):\n",
    "    return 1/(1+ np.exp(-x))\n",
    "\n",
    "# unit_step\n",
    "    # Inputs:    x: Multi-dimensional array with size N along the first axis \n",
    "    # \n",
    "    # Returns:   out: Multi-dimensional array with same size of x \n",
    "\n",
    "def unit_step(x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     N,W = len(x),len(x[0])\n",
    "#     out = np.zeros((N,W))\n",
    "#     for i in range(N):\n",
    "#         for j in range(W):\n",
    "#             if(x[i][j] > 0):\n",
    "#                 out[i][j] = 1\n",
    "    \n",
    "    out = np.heaviside(x, 0)\n",
    "\n",
    "    return out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve2D\n",
    "    # Inputs:    X: [N x height x width x num_channels]\n",
    "    #            filters: [num_filters x filter_height x filter_width x num_input_channels]\n",
    "    # \n",
    "    # Returns:   Xc: output array by convoling X and filters. [N x output_height x output_width x num_filters]\n",
    "\n",
    "def convolve2D(X0, filters):\n",
    "   \n",
    "    N, X0_len, _, num_ch = X0.shape\n",
    "    num_out_ch, filter_len, _, _ = filters.shape\n",
    "    F0_side = X0_len - filter_len + 1\n",
    "\n",
    "    F0 = np.zeros((N, F0_side, F0_side, num_out_ch))\n",
    "#     print(\"N\",N)\n",
    "#     print(\"num_out ch\", num_out_ch)\n",
    "#     print(\"num ch\", num_ch)\n",
    "    # Images\n",
    "    for n in range(N):\n",
    "        #filter number\n",
    "        for o_ch in range(num_out_ch):\n",
    "            #channel number\n",
    "            for ch in range(num_ch):\n",
    "                # Get the right image and filter for conv\n",
    "                image = np.zeros((X0_len,X0_len))\n",
    "                Filter = np.zeros((filter_len,filter_len))\n",
    "                for i in range(X0_len):\n",
    "                    for j in range(X0_len):\n",
    "                        image[i][j] = X0[n][i][j][ch]\n",
    "                for i in range(filter_len):\n",
    "                    for j in range(filter_len):\n",
    "                        Filter[i][j] = filters[o_ch][i][j][ch]\n",
    "                # Perform convolution\n",
    "                out_conv = signal.convolve2d(image,Filter,mode='valid')\n",
    "                #Load ret var with correct output of conv\n",
    "                # Use the sum because we sum the three channels of rgb in output\n",
    "                for i in range(F0_side):\n",
    "                    for j in range(F0_side):\n",
    "                        F0[n][i][j][o_ch] += out_conv[i][j]\n",
    "                \n",
    "    return F0\n",
    "\n",
    "\n",
    "# maxPool\n",
    "    # Inputs:    R0: [N x height x width x num_channels]\n",
    "    #            mp_len: size of max pool window, also the stride for this MP\n",
    "    # \n",
    "    # Returns:   p_out: output of pooling R0. [N x output_height x output_width x num_channels]\n",
    "    #            R0_mask: A binary mask with the same size as R0. Indicates which index was chosen to be the max\n",
    "    #            for each max pool window. This will be used for backpropagation.\n",
    "\n",
    "def maxPool(R0, mp_len):\n",
    "\n",
    "    N, R0_len, _, num_ch = R0.shape\n",
    "    p_out_len = int((R0_len-mp_len)/mp_len + 1)\n",
    "\n",
    "    R0_mask = np.zeros(R0.shape)\n",
    "    p_out = np.zeros((N, p_out_len, p_out_len, num_ch))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for ch in range(num_ch):\n",
    "            for row in range(p_out_len): \n",
    "                for col in range(p_out_len):\n",
    "                    # YOUR CODE HERE\n",
    "                    cells = []\n",
    "                    for i in range(mp_len):\n",
    "                        for j in range(mp_len):\n",
    "                            if((row * mp_len + i) < R0_len  and (col * mp_len + j) < R0_len ):\n",
    "                                cells.append(R0[n][row * mp_len + i][col * mp_len + j][ch])\n",
    "                            else:\n",
    "                                cells.append(0)\n",
    "                    p_out[n][row][col][ch] = np.max(cells)\n",
    "                    pool_index = np.argmax(cells)\n",
    "#                     print(len(cells))\n",
    "#                     for i in range(mp_len):\n",
    "#                         for j in range(mp_len):\n",
    "#                             if((row * mp_len + i) < R0_len  and (col * mp_len + j) < R0_len ):\n",
    "#                                 R0_mask[n][row * mp_len + i][col * mp_len + j][ch] = pool_index                    \n",
    "                    \n",
    "                    \n",
    "#                     window = R0[n,row*mp_len:(row+1)*mp_len-1,col*mp_len:(col+1)*mp_len-1,ch]\n",
    "#                     window = np.array(window)\n",
    "#                     max_val = window.max()\n",
    "#                     p_out[n][row][col][ch] = max_val\n",
    "                    i,j = np.unravel_index(pool_index, (mp_len,mp_len))\n",
    "                    R0_mask[n][i+row*mp_len][j+col*mp_len][ch] = 1\n",
    "#                     if (n == 2) and (ch == 2) and (row == 2) and (col == 2):\n",
    "#                         print(window)\n",
    "#                         print(R0_mask[n,row*mp_len:(row+1)*mp_len-1,col*mp_len:(col+1)*mp_len-1,ch])\n",
    "\n",
    "    return p_out, R0_mask\n",
    "\n",
    "# fc\n",
    "    # Inputs:    X: [N x num_input_features]\n",
    "    #            W: [num_input_features x num_fc_nodes]\n",
    "    # \n",
    "    # Returns:   out: Linear combination of X and W. [N x num_fc_nodes]\n",
    "\n",
    "def fc(X, W):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    out = np.dot(X,W)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_fwd\n",
    "    # Inputs:    X0: batch of images. [N x img_height x img_width x num_channels]\n",
    "    #            W0, W1, W2: Parameters of the CNN\n",
    "    #            mp_len: the length of one side of the max pool window\n",
    "    # \n",
    "    # Returns:   sig: vector containing the output for each sample. [N x 1]\n",
    "    #            cache: a dict containing the relevant output layer calculations that will be\n",
    "    #            used in backpropagation\n",
    "    \n",
    "def cnn_fwd(X0, W0, W1, W2, mp_len):\n",
    "    \n",
    "    # F0 \n",
    "    # YOUR CODE HERE\n",
    "    F0 = convolve2D(X0, W0)\n",
    "    R0 = relu(F0)\n",
    "    # X1p \n",
    "    # YOUR CODE HERE\n",
    "    X1p, R0_mask = maxPool(R0, mp_len)\n",
    "    # X1 (flatten)\n",
    "    # YOUR CODE HERE\n",
    "    X1 = X1p.reshape(len(X0),-1)\n",
    "    # FC Layers\n",
    "    # YOUR CODE HERE\n",
    "    F1 = fc(X1,W1)\n",
    "    X2 = relu2(F1)\n",
    "    F2 = fc(X2,W2)\n",
    "    # Output\n",
    "    # YOUR CODE HERE\n",
    "    sig = sigmoid(F2)\n",
    "    # Save outputs of functions for backward pass\n",
    "    cache = {\n",
    "        \"F0\":F0,\n",
    "        \"R0\":R0,\n",
    "        \"X1p\":X1p,\n",
    "        \"R0m\":R0_mask,\n",
    "        \"X1\":X1,\n",
    "        \"F1\":F1,\n",
    "        \"X2\":X2,\n",
    "        \"F2\":F2      \n",
    "    }\n",
    "    \n",
    "    return sig, cache\n",
    "\n",
    "\n",
    "# loss\n",
    "    # Inputs:    sig: vector containing the CNN output for each sample. [N x 1]\n",
    "    #            Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    # \n",
    "    # Returns:   L: Loss/error criterion for the model. \n",
    "\n",
    "def loss(sig, Y):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    N = len(sig)\n",
    "    L = 0\n",
    "    for i in range(N):\n",
    "        L += -Y[i]*np.log(sig[i]) - (1- Y[i])*np.log(1-sig[i])\n",
    "    L = L/N\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprop Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolve2DBwd\n",
    "    # Inputs:    X0: batch of images. [N x height x width x num_channels]\n",
    "    #            dL_dF0: Gradient at the output of the conv layer. \n",
    "    # \n",
    "    # Returns:   dL_dW0. gradient of loss L wrt W0. Same size as W0\n",
    "\n",
    "def convolve2DBwd(X0, dL_dF0):\n",
    "    \n",
    "    N, X0_len, _, num_ch = X0.shape\n",
    "    _, dL_dF0_len, _, num_out_ch  = dL_dF0.shape\n",
    "    filter_len = X0_len - dL_dF0_len + 1\n",
    "    \n",
    "    dL_dW0 = np.zeros((num_out_ch, filter_len, filter_len, num_ch))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for o_ch in range(num_out_ch):\n",
    "            for ch in range(num_ch):\n",
    "                # YOUR CODE HERE \n",
    "                A = X0[n,:,:,ch]\n",
    "                B = dL_dF0[n,:,:,o_ch]\n",
    "                #reverse A\n",
    "                A_ = np.fliplr( np.flip(A,axis=0)) \n",
    "#                 A_ = np.zeros(A.shape)\n",
    "#                 for i in range(A.shape[0]):\n",
    "#                     for j in range(A.shape[1]):\n",
    "#                         A_[i][j] = A[-i][-j]\n",
    "#                 if (n == 0) and (o_ch == 0) and (ch == 0):\n",
    "#                     print(A)\n",
    "#                     print(A_)\n",
    "                corr = signal.convolve2d(B, A_, mode='valid')    \n",
    "                dL_dW0[o_ch,:,:,ch] += corr\n",
    "    \n",
    "    return dL_dW0\n",
    "\n",
    "\n",
    "# maxPoolBwd\n",
    "    # Inputs:    dL_dX1p: Gradient at the output of the MaxPool layer\n",
    "    #            R0_mask: A binary mask with the same size as R0. Defined in maxPool\n",
    "    #            mp_len: the length of one side of the max pool window\n",
    "    # \n",
    "    # Returns:   dL_dR0: Gradient at the output of ReLu\n",
    "    \n",
    "def maxPoolBwd(dL_dX1p, R0_mask,  mp_len):\n",
    "    \n",
    "    N, H, W, C = R0_mask.shape\n",
    "    N, dH, dW, C = dL_dX1p.shape\n",
    "    \n",
    "    dL_dR0 = np.zeros(R0_mask.shape)\n",
    "    \n",
    "    for n in range(N):\n",
    "        for ch in range(C):\n",
    "            for row in range(dH):\n",
    "                for col in range(dW):\n",
    "                    # YOUR CODE HERE\n",
    "                    window = R0_mask[n,row*mp_len:(row+1)*mp_len-1,col*mp_len:(col+1)*mp_len-1,ch]\n",
    "                    i,j = np.unravel_index(window.argmax(), window.shape)                    \n",
    "                    dL_dR0[n][i+row*mp_len][j+col*mp_len][ch] = dL_dX1p[n][row][col][ch]\n",
    "#                     if (n == 0) and (ch == 0) and (row == 0) and (col == 0):\n",
    "#                         print(window)\n",
    "#                         print(dL_dR0[n,row*mp_len:(row+1)*mp_len-1,col*mp_len:(col+1)*mp_len-1,ch])\n",
    "#                         print(i,j)\n",
    "                    \n",
    "    return dL_dR0\n",
    "\n",
    "def dL_dF2(Y, cache):\n",
    "    N = len(Y)\n",
    "    F2 = cache['F2']\n",
    "    dL_dF2 = np.zeros((N,1))\n",
    "    for i in range(N):\n",
    "        dL_dF2[i] = (-1*Y[i]*(1-sigmoid(F2[i])) + (1-Y[i])*sigmoid(F2[i]))\n",
    "    dL_dF2 /= N\n",
    "    return dL_dF2\n",
    "\n",
    "# dL_dW2\n",
    "    # Inputs:    Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dW2: Gradient of the Loss wrt W2\n",
    "    \n",
    "def dL_dW2(Y, cache):\n",
    "   \n",
    "    # YOUR CODE HERE\n",
    "#     N = len(Y)\n",
    "#     f2 = cache[\"F2\"]\n",
    "#     x2 = cache[\"X2\"]\n",
    "#     sig = sigmoid(f2)\n",
    "#     dL_dW2 = 0\n",
    "#     for i in range(N):\n",
    "#         dL_dW2 += np.outer(sig[i]-Y[i],x2[i])\n",
    "#     dL_dW2 = dL_dW2/N\n",
    "#     dL_dW2 = dL_dW2.T\n",
    "\n",
    "    dLdF2 = dL_dF2(Y, cache)\n",
    "    X2 = cache['X2']\n",
    "    dF2_dW2 = X2\n",
    "    dL_dW2 = np.matmul(dF2_dW2.T, dLdF2)\n",
    "    \n",
    "    \n",
    "    return dL_dW2    \n",
    "\n",
    "# dL_dW1\n",
    "    # Inputs:    Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    #            W2: Weight matrix for the second FC layer\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dW1: Gradient of the Loss wrt W1\n",
    "    \n",
    "def dL_dW1(Y, W2, cache):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "#     N = len(Y)\n",
    "#     f2 = cache[\"F2\"]\n",
    "#     f1 = cache[\"F1\"]\n",
    "#     x1 = cache[\"X1\"]\n",
    "#     sig = sigmoid(f2)\n",
    "#     unit = unit_step(f1) \n",
    "#     dL_dW1 = 0\n",
    "#     for i in range(N):\n",
    "#         dL_dW1 += np.outer( np.dot(sig[i]-Y[i], np.transpose(W2)) *unit[i]  ,x1[i])   \n",
    "#     dL_dW1 = dL_dW1/N\n",
    "#     dL_dW1 = dL_dW1.T\n",
    "\n",
    "    F1 = cache['F1']\n",
    "    X1 = cache['X1']\n",
    "    dLdF2 = dL_dF2(Y, cache)\n",
    "    dF2dX2 = W2\n",
    "    dX2dF1 = unit_step(F1)\n",
    "    dF1dW1 = X1\n",
    "    A = np.matmul(dLdF2, dF2dX2.T)\n",
    "    B = A * dX2dF1\n",
    "    dL_dW1 = np.matmul(dF1dW1.T, B)\n",
    "    return dL_dW1\n",
    "    \n",
    "#     return dL_dW1\n",
    "\n",
    "\n",
    "# dL_dW0\n",
    "    # Inputs:    X0: batch of images. [N x height x width x num_channels]\n",
    "    #            Y: vector containing the ground truth label for each sample. [N x 1]\n",
    "    #            W1: Weight matrix for the first FC layer\n",
    "    #            W2: Weight matrix for the second FC layer\n",
    "    #            mp_len: the length of one side of the max pool window\n",
    "    #            cache: a dict containing the relevant output layer calculations \n",
    "    # \n",
    "    # Returns:   dL_dW0: Gradient of the Loss wrt W0\n",
    "\n",
    "def dL_dW0(X0, Y, W1, W2, mp_len, cache):\n",
    "    \n",
    "    N, X1p_len, _, no_out_ch  = cache['X1p'].shape\n",
    "    F2 = cache['F2']\n",
    "    F1 = cache['F1']\n",
    "    R0m = cache['R0m']\n",
    "    F0 = cache['F0']\n",
    "    \n",
    "    #dL_dF2\n",
    "    # YOUR CODE HERE\n",
    "    dLdF2 = dL_dF2(Y, cache)   \n",
    "    \n",
    "    #dL_dF1\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    dF2_dX2 = W2\n",
    "    dX2_dF1 = unit_step(F1)\n",
    "    dL_dF1 = np.matmul(dLdF2, dF2_dX2.T) * dX2_dF1  \n",
    "    print(np.matmul(dLdF2, dF2_dX2.T).shape)\n",
    "    print(dX2_dF1.shape)\n",
    "    #dL_dX1\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    dF1_dX1 = W1\n",
    "    dL_dX1 = np.matmul(dL_dF1, dF1_dX1.T)\n",
    "    \n",
    "    # dL_dX1p (unflatten)\n",
    "    # YOUR CODE HERE\n",
    "    dL_dX1p = dL_dX1.reshape(cache['X1p'].shape) \n",
    "    \n",
    "    # dL_dR0 (unpool)\n",
    "    # YOUR CODE HERE\n",
    "    dL_dR0 = maxPoolBwd(dL_dX1p, R0m, mp_len)\n",
    "    \n",
    "    # dL_dF0 (relu_bwd)\n",
    "    # YOUR CODE HERE\n",
    "    dR0_dF0 = unit_step(F0)\n",
    "    dL_dF0 = dL_dR0 * dR0_dF0\n",
    "    \n",
    "    # dL_dW0\n",
    "    # YOUR CODE HERE\n",
    "    dL_dW0 = convolve2DBwd(X0, dL_dF0)\n",
    "\n",
    "    return dL_dW0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "[[8 7 6]\n",
      " [5 4 3]\n",
      " [2 1 0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(9).reshape(3,3)\n",
    "a_ = np.fliplr( np.flip(a,axis=0)) \n",
    "print(a)\n",
    "print(a_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000 training images\n",
      "Loaded 800 validation images\n"
     ]
    }
   ],
   "source": [
    "# Load images and scale them\n",
    "# YOUR CODE HERE\n",
    "ts, vs = load_images()\n",
    "#normalize\n",
    "train_set = []\n",
    "train_set.append(ts[0].astype(float))\n",
    "train_set.append(ts[1])\n",
    "\n",
    "val_set = []\n",
    "val_set.append(vs[0].astype(float))\n",
    "val_set.append(vs[1])\n",
    "\n",
    "for n in range(len(train_set[0])):\n",
    "    for i in range(len(train_set[0][0])):\n",
    "        for j in range(len(train_set[0][0][0])):\n",
    "            for ch in range(len(train_set[0][0][0][0])):\n",
    "                train_set[0][n][i][j][ch] = train_set[0][n][i][j][ch] /255\n",
    "\n",
    "for n in range(len(val_set[0])):\n",
    "    for i in range(len(val_set[0][0])):\n",
    "        for j in range(len(val_set[0][0][0])):\n",
    "            for ch in range(len(val_set[0][0][0][0])):\n",
    "                val_set[0][n][i][j][ch] = val_set[0][n][i][j][ch] /255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 20\n",
    "lr = 0.1\n",
    "batch_size = 16\n",
    "filter_len = 5\n",
    "num_out_ch = 3\n",
    "mp_len = 12\n",
    "fc_nodes = 2\n",
    "\n",
    "# Declare weights\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e48c3b83d751>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# YOUR CODE HERE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mb_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_batches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_batches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_batches' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    \n",
    "    # make set of batches\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    for b_idx in range(num_batches):\n",
    "        X = img_batches[b_idx]\n",
    "        Y = label_batches[b_idx]\n",
    "        \n",
    "        # Forward pass\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Calculate gradients\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # Update gradients\n",
    "        # YOUR CODE HERE\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Correctness of Forward and Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0 dim (3, 5, 5, 3)\n",
      "W1 dim (192, 2)\n",
      "W2 dim (2, 1)\n",
      "finished fwd\n",
      "train_loss: [ 0.23271396] train_acc: 0.9175\n"
     ]
    }
   ],
   "source": [
    "weights = np.load('weights.npz')\n",
    "W0 = weights['W0']\n",
    "W1 = weights['W1']\n",
    "W2 = weights['W2']\n",
    "print(\"W0 dim\", W0.shape)\n",
    "print(\"W1 dim\", W1.shape)\n",
    "print(\"W2 dim\", W2.shape)\n",
    "sig, _ = cnn_fwd(val_set[0], W0, W1, W2, mp_len)\n",
    "train_acc = 0\n",
    "for i in range(len(sig)):\n",
    "    if(np.round(sig[i])==val_set[1][i]):\n",
    "        train_acc +=1\n",
    "train_acc = (train_acc/len(sig))\n",
    "\n",
    "print(\"train_loss:\", loss(sig, val_set[1]), \"train_acc:\", train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 2)\n",
      "(16, 2)\n",
      "W2 value: -834.631617647\n",
      "W1 value: -452.631617647\n",
      "W0 value: -512.075735294\n"
     ]
    }
   ],
   "source": [
    "# Make backprop testing batch\n",
    "X_bp = np.vstack([train_set[0][0:8,:,:,:], train_set[0][-9:-1,:,:,:]])\n",
    "Y_bp = np.vstack([train_set[1][0:8], train_set[1][-9:-1]])\n",
    "\n",
    "# Initialize weights to all ones\n",
    "# YOUR CODE HERE\n",
    "W0 = np.ones((3,5,5,3))\n",
    "W1 = np.ones((192,2))\n",
    "W2 = np.ones((2,1))\n",
    "# Update weights once\n",
    "# YOUR CODE HERE\n",
    "sig, cache = cnn_fwd(X_bp,W0,W1,W2, mp_len)\n",
    "W2_grad = (dL_dW2(Y_bp,cache))\n",
    "W1_grad = dL_dW1(Y_bp,W2,cache)\n",
    "W0_grad = dL_dW0(X_bp, Y_bp, W1, W2, mp_len, cache)\n",
    "\n",
    "W2 = W2 - lr* W2_grad\n",
    "W1 = W1 - lr* W1_grad\n",
    "W0 = W0 - lr* W0_grad\n",
    "\n",
    "# print(dL_dW0(X_bp, Y_bp, W1, W2, mp_len, cache))\n",
    "print(\"W2 value:\", np.sum(W2))\n",
    "print(\"W1 value:\", np.sum(W1))\n",
    "print(\"W0 value:\", np.sum(W0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
