{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "train will have the training samples and test will have the test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speaker dependent partitions\n",
    "#sdeptrain dimensions sdeptrain[speaker][word][utterance idx] with idxs given alphabetically\n",
    "sdeptrain = [[[[] for i in range(4)] for j in range(5)] for k in range(4)]\n",
    "#sdeptest dimensions sdeptrain[speaker][word] with idxs given alphabetically\n",
    "sdeptest = [[[] for i in range(5)] for j in range(4)]\n",
    "p = './feature'\n",
    "speakerList = ['dg', 'ls', 'mh', 'yx']\n",
    "wordList = ['asr','cnn','dnn','hmm','tts']\n",
    "snum = 0\n",
    "for s in speakerList:\n",
    "    speakerpath = p+'/'+s\n",
    "    wnum = 0\n",
    "    for w in wordList:\n",
    "        wordpath = speakerpath +'/'+s+'_'+w\n",
    "        #set up train\n",
    "        for utt in range(1,5):\n",
    "            fpath = wordpath + str(utt)+'.fea'\n",
    "            f = open(fpath,'r')\n",
    "            data = f.readlines()\n",
    "            data = [i.split(',') for i in data]\n",
    "            for sample in range(len(data)):\n",
    "                data[sample] = [float(i) for i in data[sample]]\n",
    "            for d in data:\n",
    "                sdeptrain[snum][wnum][utt-1].append(d)\n",
    "        #set up test\n",
    "        fpath2 = wordpath + str(5)+'.fea'\n",
    "        f2 = open(fpath2,'r')\n",
    "        data = f2.readlines()\n",
    "        data = [i.split(',') for i in data]\n",
    "        for d in data:\n",
    "            sdeptest[snum][wnum].append(d)\n",
    "        wnum += 1\n",
    "    snum += 1\n",
    "sdeptrain = np.array(sdeptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sdeptrain[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speaker independent partitions\n",
    "#Extract feature vectors\n",
    "p = './feature'\n",
    "#test separetes each utterance of each word of each speaker\n",
    "test = []\n",
    "train = []\n",
    "#test_big chunks all utterances of each word for each speaker\n",
    "test_big = []\n",
    "train_big = []\n",
    "dirList = ['dg', 'ls', 'mh', 'yx']\n",
    "for d in os.listdir(p):\n",
    "    #put mh in the test set\n",
    "    if d == 'mh':\n",
    "        dirpath = p + '/' + d\n",
    "        filelist = os.listdir(dirpath)\n",
    "        word = [[] for i in range(5)]\n",
    "        word_big = [[] for i in range(5)]\n",
    "        for i in range(len(filelist)):\n",
    "            f = open(dirpath + '/' + filelist[i])\n",
    "            data_ = f.readlines() \n",
    "            data = [i.split(',') for i in data_]\n",
    "            for sample in range(len(data)):\n",
    "                data[sample] = [float(s) for s in data[sample] ]\n",
    "            word[i//5].append(data)\n",
    "            word_big[i//5].extend(data)\n",
    "        test.append(word)\n",
    "        test_big.append(word_big)\n",
    "    else:\n",
    "        if d in dirList:\n",
    "            #put all others in train\n",
    "            dirpath = p + '/' + d\n",
    "            filelist = os.listdir(dirpath)\n",
    "            word = [[] for i in range(5)]\n",
    "            word_big = [[] for i in range(5)]\n",
    "            for i in range(len(filelist)):\n",
    "                f = open(dirpath + '/' + filelist[i])\n",
    "                data_ = f.readlines() \n",
    "                data = [i.split(',') for i in data_]\n",
    "                for sample in range(len(data)):\n",
    "                    data[sample] = [float(s) for s in data[sample] ]\n",
    "                word[i//5].append(data)\n",
    "                word_big[i//5].extend(data)\n",
    "            train.append(word)\n",
    "            train_big.append(word_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5\n"
     ]
    }
   ],
   "source": [
    "print(len(train_big),len(train_big[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.71828182846\n"
     ]
    }
   ],
   "source": [
    "#speaker dependent hmm\n",
    "\n",
    "print(np.exp(1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fdsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HELPER FUNCTIONSSSSS\n",
    "#implemented from https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm\n",
    "\n",
    "#Forward Pass\n",
    "\n",
    "def calculateB(x, mu, sigma, n):\n",
    "    #n denotes which state we are in {1...N} N = 5\n",
    "    #x is a single time frame (1x14)\n",
    "    #mu is the average across all states \n",
    "    #sigma is the covariance matrix across all states \n",
    "    \n",
    "    #Conputes the Gaussian shit\n",
    "    D = len(sigma)\n",
    "    C = ((2 * math.pi)**(D/2) * (np.linalg.det(sigma[n]))**(0.5))**(-1)\n",
    "    power = (-0.5) * ((x - mu[n]).T) * (np.linalf.det(sigma[n]))**(-1) * (x - mu[n])\n",
    "    return C * np.exp(power)\n",
    "\n",
    "def calculateAlpha(priors, transMatrix, X, mu, sigma, n, t, N):\n",
    "    #priors is the initial probabilities (pi)\n",
    "    #transMatrix is the transition matrix\n",
    "    #X is the set of all observations. For that file?\n",
    "    #mu is the average across the features for all states\n",
    "    #sigma is the covariance matrices for all states\n",
    "    #n is the current state we care about\n",
    "    #t is the current observation we care about\n",
    "    #N is the total number of states\n",
    "    \n",
    "    #do this shit recursively\n",
    "    #hopefully it shouldnt take too long?\n",
    "    #memoize alpha if it does\n",
    "    \n",
    "    if t == 0:\n",
    "        #if we are in the first time frame\n",
    "        alpha_1 = priors[n] * computeB(X[t], mu, sigma, n)\n",
    "        return alpha_1\n",
    "    else:\n",
    "        #will we get index out of bounds errors w the X[t+1]\n",
    "        b = computeB(X[t+1], mu, sigma, n)\n",
    "        s = 0\n",
    "        for i in range(N):\n",
    "            #there should be only two nonzero values for t because of the transition matrix\n",
    "            temp = computeAlpha(priors, transMatrix, X, mu, i, t, N) * transMatrix[i][n]\n",
    "            s += temp\n",
    "        alpha_1 = b * s\n",
    "        return alpha_1\n",
    "       \n",
    "#Backward Pass\n",
    "\n",
    "def calculateBeta(transMatrix, X, mu, sigma, n, t, N, T):\n",
    "    #Do this shit recursively as well\n",
    "    \n",
    "    if t == T:\n",
    "        #if we are at the last time step\n",
    "        Beta = 1\n",
    "        return Beta\n",
    "    else:\n",
    "        Beta = 0\n",
    "        for i in range(N):\n",
    "            #iterate through all the states\n",
    "            #t should only have one nonzero values (bc of the transition matrix)\n",
    "            temp += computeBeta(transMatrix, X, mu, sigma, i, t+1, N, T) * transMatrix[n][i] * computeB(X[t+1], mu, sigma,i)\n",
    "            Beta += temp\n",
    "        return Beta\n",
    "    \n",
    "#Update step helper functions\n",
    "\n",
    "def calculateGamma(priors, transMatrix, X, mu, sigma, n, t, N, T):\n",
    "    #denominator should be the same as xi denominator\n",
    "    num = calculateAlpha(priors, transMatrix, X, mu, sigma, n, t, N)*calculateBeta(X, transMatrix, mu, sigma, n, t, T, N)\n",
    "    denom = 0\n",
    "    for i in range(N):\n",
    "        #for each state\n",
    "        temp =calculateAlpha(priors, transMatrix, X, mu, sigma, i, t, N)*calculateBeta(X, transMatrix, mu, sigma, i, t, T, N)\n",
    "        denom += temp\n",
    "    gamma = num / denom\n",
    "    return gamma\n",
    "\n",
    "def calculateXi( transMatrix, X, mu, sigma, n, j, t, N, T):\n",
    "    #caluculate xi \n",
    "    #probability of going from state n to state j at times t and t+1 respectively\n",
    "    \n",
    "    num = calculateAlpha(priors, transMatrix, X, mu, sigma, n, t, N) * transMatrix[n][j]\n",
    "    num *= calculateBeta(transMatrix, X, mu, sigma, j, t+1, N, T) * calculateB(X[t+1], mu, sigma, j)\n",
    "    denom = 0\n",
    "    for a in range(N):\n",
    "        #first state\n",
    "        for b in range(N):\n",
    "            #second state\n",
    "            temp = calculateAlpha(priors, transMatrix, X, mu, sigma, a, t, T) * transMatrix[a][b]\n",
    "            temp *= calculateBeta(transMatrix, X, mu, sigma, b, t+1, N, T ) * calculateB(X[t+1], mu, sigma, b)\n",
    "            denom += temp\n",
    "            \n",
    "    xi = num / denom\n",
    "    return xi    \n",
    "\n",
    "#Update steps\n",
    "def updatePriors(transMatrix, X, mu, sigma, n, N, T):\n",
    "    #we want the expected frequency spent in state i at time step t = 1\n",
    "    return calculateXi(priors, transMatrix, X, mu, sigma, n, 1, N, T)\n",
    "\n",
    "def updateA(priors, transMatrix, X, mu, sigma, n, j, t, N, T):\n",
    "    num = 0\n",
    "    for i in range(T-1):\n",
    "        #across all t\n",
    "        temp = calculateXi(transMatrix, X, mu, sigma, n, j, i, N, T)\n",
    "        num += temp\n",
    "        \n",
    "    denom = 0\n",
    "    for i in range(T-1):\n",
    "        #across all t\n",
    "        temp = calculateGamma(priors, transMatrix, X, mu, sigma, n, i, N, T)\n",
    "        denom += temp\n",
    "    \n",
    "    alpha_update = num / denom\n",
    "    return alpha_update\n",
    "\n",
    "def updateB(vk, priors, transMatrix, X, mu, sigma, n, N, T):\n",
    "    #vk is a specific observation\n",
    "    #how to compare that against all the y_t?\n",
    "    num = 0\n",
    "    for i in range(T):\n",
    "        #if yt == vk:\n",
    "        temp = calculateGamma(priors, transMatrix, X, mu, sigma, n, i, N, T)\n",
    "        num += temp\n",
    "    denom = 0\n",
    "    for i in range(T):\n",
    "        temp = calculateGamma(priors, transMatrix, X, mu, sigma, n, i, N, T)\n",
    "        denom += temp\n",
    "    b_update = num / denom\n",
    "\n",
    "    return b_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speaker independent hmm\n",
    "initialProbabilities = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "\n",
    "initialTransition = [[0.8,0.2,  0,  0,   0],\n",
    "                     [  0,0.8,0.2,  0,   0],\n",
    "                     [  0,  0,0.8,0.2,   0],\n",
    "                     [  0,  0,  0,0.8, 0.2],\n",
    "                     [  0,  0,  0,  0,   1]]\n",
    "\n",
    "#create an HMM for each word\n",
    "word0 = []\n",
    "word1 = []\n",
    "word2 = []\n",
    "word3 = []\n",
    "word4 = []\n",
    "\n",
    "for speaker in range(len(train_big)):\n",
    "    for word in range(len(train_big[speaker])):\n",
    "        if word == 0:\n",
    "            word0.extend(train_big[speaker][word])\n",
    "        if word == 1:\n",
    "            word1.extend(train_big[speaker][word])\n",
    "        if word == 2:\n",
    "            word2.extend(train_big[speaker][word])\n",
    "        if word == 3:\n",
    "            word3.extend(train_big[speaker][word])\n",
    "        if word == 4:\n",
    "            word4.extend(train_big[speaker][word])\n",
    "\n",
    "#initialize mean of hmm for the first word\n",
    "word0 = np.array(word0)\n",
    "# print(word0.shape)\n",
    "#mu should be (1x14) for each state\n",
    "mu0 = np.mean(word0, axis=0)\n",
    "#initialize the covariance matrix, sigma, of the hmm for the first word\n",
    "word0_np = np.array(word0)\n",
    "#covmat should be (14x14) for each state\n",
    "covmat0 = np.cov(word0_np.T)\n",
    "\n",
    "# Baum Welch this bitchhhhhh\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments\n",
    "\n",
    "There are N = 5 possible states and the number of observations is equal to the number of rows or time steps for each utterance. At each time step or observation, we are in one of the states, so a number 1-5 i think. So T = how many ever rows there are present. Still not sure exactly how we should chunk the data. Not sure if we should separate it by utterance or if we should group all the utterances of the same word together. Update parameters using baum welch forward/backward propogation equations. According to Piazza, update alpha and beta after each individual utterance and update the transition matrix after all the files for that word? Not how to implement this though. \n",
    "\n",
    "We train one hmm per word, so 5 in total. To predict a test sample, we run the utterance through each of the 5 models and assign it the label of the hmm that gives the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.8224, -14.252, 1.6086, -0.41555, 0.055411, 0.20185, 0.41501, 0.10763, -0.033127, -0.26792, 0.0079, -0.023143, 0.30929, 0.25359]\n"
     ]
    }
   ],
   "source": [
    "# def covmat(data):\n",
    "#     #create the covariance matrix\n",
    "#     #each row is a variable\n",
    "#     #each column is an observation of each of those variables\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
